{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "self_study_py_bs4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorganLee0906/self_study/blob/main/20210606_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es3UaT91shLm"
      },
      "source": [
        "#ptt文章查詢器\n",
        "#-*-coding:utf-8 -*-\n",
        "from bs4 import BeautifulSoup as bs    #爬蟲套件\n",
        "from wordcloud import WordCloud       #文字雲套件\n",
        "import requests \n",
        "import jieba                 #文字分析套件\n",
        "import matplotlib.pyplot as plt       #顯示圖形用\n",
        "from datetime import datetime as dtime  #獲取時間用\n",
        "\n",
        "#time\n",
        "current_time = dtime.today() #get current time\n",
        "print(current_time)\n",
        "\n",
        "#File IO\n",
        "f = open('tmp.txt', 'w', encoding='UTF-8') #open tmp.txt\n",
        "f.write('') #clear file\n",
        "f.close()\n",
        "\n",
        "#requests\n",
        "s = requests.session()\n",
        "board_name = input('輸入看板名稱:')\n",
        "next_page_url = 'https://www.ptt.cc/bbs/'+board_name+'/index.html'\n",
        "\n",
        "#search data\n",
        "mm_min , dd_min = map(int, input('輸入日期(該日期以後的文章)(mm dd)').split(' '))\n",
        "mm_max , dd_max = map(int, input('輸入日期(該日期以前的文章)(mm dd)').split(' '))\n",
        "val_min = int(input('搜尋推文數高於多少(<0則搜噓文數)的文章:'))\n",
        "\n",
        "date_flag = True #check date range\n",
        "count = 0\n",
        "\n",
        "while date_flag:\n",
        "  count += 1\n",
        "  res = s.get(next_page_url)\n",
        "\n",
        "  soup = bs(res.text, 'html.parser')\n",
        "  div_tags = soup.find_all('div', {'class': 'title'}) #爬當前頁面所有文章標題\n",
        "  val_tags = soup.find_all('div', {'class': 'nrec'}) #爬當前頁面所有推薦值\n",
        "  date_tags = soup.find_all('div', {'class': 'date'}) #爬當前頁面所有日期標籤\n",
        "  btn = soup.select('div.btn-group > a')\n",
        "  up_page_href = btn[3]['href']\n",
        "\n",
        "  article_list = [] #list of article title\n",
        "  pushval_list = [] #list of article value\n",
        "  artinfo_list = [] #list of article date\n",
        "\n",
        "  for val_tag, div_tag, date_tag in zip(val_tags, div_tags, date_tags):\n",
        "    num_tag= val_tag.find('span')\n",
        "    a_tag = div_tag.find('a')\n",
        "    d_tag = date_tag.get_text()\n",
        "    artinfo_list.append(d_tag)\n",
        "    if num_tag is None:\n",
        "      pushval_list.append(0)\n",
        "    else:\n",
        "      pushval_list.append(num_tag.text)\n",
        "    if a_tag is not None:\n",
        "      article_list.append(a_tag.text)\n",
        "    else:\n",
        "      article_list.append('本文章已被刪除')\n",
        "\n",
        "  '''\n",
        "  註：因BBS的文章列表順序為由下往上排序，因此在加到tmp.txt前須先反轉list\n",
        "  '''\n",
        "  article_list.reverse()\n",
        "  pushval_list.reverse()\n",
        "  artinfo_list.reverse()\n",
        "\n",
        "  f = open('tmp.txt', 'a', encoding='UTF-8')\n",
        "  ft = open('/content/drive/MyDrive/Colab Notebooks/python 爬蟲/'+str(mm_min)+str(dd_min)+'-'+str(mm_max)+str(dd_max)+'_'+board_name, 'a', encoding='UTF-8')\n",
        "  \n",
        "  for date, val, title in zip(artinfo_list, pushval_list, article_list):\n",
        "    if title !='本文章已被刪除':\n",
        "      appe = title[(title.find(']')+1):]\n",
        "    m,d = map(int, date.split('/'))\n",
        "    if m < mm_max or (m==mm_max and d<=dd_max):\n",
        "      f.write(appe+'\\n')\n",
        "      ft.write(str(date+'\\t'+str(val)+'\\t'+title+'\\n'))\n",
        "    '''\n",
        "    註：因部分看板的置底文日期過早，導致程式檢查日期是可能會因此誤判。因此在檢查日期時不會檢查BBS WEB版的第一頁文章的所有日期，\n",
        "    但可能因為這樣，在爬較少文章的看板時出錯。由於本次專案主要爬的是Stock版，屬於前十大看板，因此較不容易發生問題。\n",
        "    若日後要爬其他看板，可能需要再修正判斷方式。\n",
        "    '''\n",
        "    if (m<mm_min or (m == mm_min and d < dd_min)) and count!=1:#檢查日期是否超出範圍\n",
        "      date_flag = False\n",
        "      break\n",
        "    if type(val) == str:\n",
        "      if val == '爆':\n",
        "        val = 100\n",
        "      elif val[0] == 'X':\n",
        "        if val == 'XX':\n",
        "          val = int(-100)\n",
        "        else: \n",
        "          val = int(val[1])*-10\n",
        "      val = int(val)\n",
        "      #print(val)\n",
        "    if val_min>=0:\n",
        "      if val>=val_min:\n",
        "        if (val == 100):\n",
        "          print(date, '爆', title, sep = '\\t')\n",
        "        else:\n",
        "          print(date, val, title, sep = '\\t')\n",
        "    else:\n",
        "      if val<=val_min:\n",
        "        if (val == -100):\n",
        "          print(date, 'XX', title, sep = '\\t')\n",
        "        else:\n",
        "          print(date, ('X'+str(int(val/-10))), title, sep = '\\t')\n",
        "  f.close()\n",
        "  ft.close()\n",
        "  if (date_flag) == False:\n",
        "    break\n",
        "  next_page_url = 'https://www.ptt.cc' + up_page_href\n",
        "\n",
        "with open('tmp.txt', 'r', encoding = 'UTF-8') as rfile:\n",
        "  text = rfile.read()\n",
        "jieba.set_dictionary('/content/drive/MyDrive/Colab Notebooks/python 爬蟲/dict.txt')\n",
        "wlist = jieba.cut(text)\n",
        "words = \" \".join(wlist)\n",
        "countword = dict()\n",
        "wordlist = words.split(' ')\n",
        "for word in wordlist:\n",
        "  if word.isalpha():\n",
        "    #print(word)\n",
        "    if word in countword:\n",
        "      countword[word] = countword.get(word)+1\n",
        "    else:\n",
        "      countword[word] = 1\n",
        "fl = open('/content/drive/MyDrive/Colab Notebooks/python 爬蟲/'+str(mm_min)+str(dd_min)+'-'+str(mm_max)+str(dd_max)+'_'+board_name+'_list.csv', 'a', encoding='UTF-8')\n",
        "for word in countword:\n",
        "  print(word, countword[word])\n",
        "  fl.write(str(word)+','+str(countword[word])+'\\n')\n",
        "fl.close()\n",
        "wc = WordCloud(width = 1080, height = 1080, scale = 3, min_font_size=50, max_font_size=300, background_color='white', collocations=False, font_path='/content/drive/MyDrive/Colab Notebooks/python 爬蟲/SourceHanSansTW-Regular.otf').generate(words)\n",
        "plt.imshow(wc)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
